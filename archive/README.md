# Archive - Legacy KTransformers Code

This directory contains the original integrated KTransformers framework code that has been archived as part of the repository restructuring.

## ğŸ“‹ What's Here

This archive preserves the complete original KTransformers implementation, including:

- **Core Framework** (`ktransformers/`): Original integrated inference framework
- **C/C++ Extensions** (`csrc/`): Low-level kernel implementations
- **Third-party Dependencies** (`third_party/`): Vendored external libraries
- **Git Submodules** (`.gitmodules`): Complete submodule configuration for legacy dependencies
- **Build System**: Installation scripts, Dockerfiles, and configuration files
- **Legacy Documentation**: Original README files with full quick-start guides

## ğŸ“š Documentation

### Original README Files

- **[English README (Legacy)](./README_LEGACY.md)**: Complete original English documentation with:
  - Quick Start guides
  - Show cases and benchmarks
  - Injection tutorial
  - Full installation instructions

- **[ä¸­æ–‡ README (Legacy)](./README_ZH_LEGACY.md)**: å®Œæ•´çš„åŸå§‹ä¸­æ–‡æ–‡æ¡£ï¼ŒåŒ…å«ï¼š
  - å¿«é€Ÿå…¥é—¨æŒ‡å—
  - æ¡ˆä¾‹å±•ç¤ºå’ŒåŸºå‡†æµ‹è¯•
  - æ³¨å…¥æ•™ç¨‹
  - å®Œæ•´å®‰è£…è¯´æ˜

## ğŸ”„ Migration to New Structure

The KTransformers project has evolved into two focused modules:

### For Inference (CPU-optimized kernels):
â†’ Use **[kt-kernel](../kt-kernel/)** instead

### For Fine-tuning (LLaMA-Factory integration):
â†’ Use **[KT-SFT](../KT-SFT/)** instead

## âš ï¸ Status

This code is **archived for reference only**. For active development and support:

- **Inference**: See [kt-kernel](../kt-kernel/)
- **Fine-tuning**: See [KT-SFT](../KT-SFT/)
- **Documentation**: See [doc](../doc/) directory
- **Issues**: Visit [GitHub Issues](https://github.com/kvcache-ai/ktransformers/issues)

## ğŸ”§ Git Submodules (For Researchers)

The root `.gitmodules` only contains kt-kernel's dependencies to keep the repository lightweight. If you need to build the legacy code, you can use the archived submodule configuration:

```bash
# Copy the complete submodule configuration
cp archive/.gitmodules .gitmodules

# Initialize legacy submodules
git submodule update --init --recursive archive/third_party/
```

**Note**: This will download ~500MB of additional dependencies.

## ğŸ“¦ Contents Overview

```
archive/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ README_LEGACY.md       # Original English documentation
â”œâ”€â”€ README_ZH_LEGACY.md    # Original Chinese documentation
â”œâ”€â”€ .gitmodules            # Complete git submodule configuration (7 legacy submodules)
â”œâ”€â”€ ktransformers/         # Original framework code
â”œâ”€â”€ csrc/                  # C/C++ extensions
â”œâ”€â”€ third_party/           # External dependencies (submodules not initialized by default)
â”œâ”€â”€ setup.py               # Original installation script
â”œâ”€â”€ pyproject.toml         # Python project configuration
â”œâ”€â”€ Dockerfile*            # Container configurations
â”œâ”€â”€ install*.sh            # Installation scripts
â””â”€â”€ ...                    # Other legacy files
```

## ğŸ’¡ Why Archived?

The original monolithic framework has been refactored into modular components for:

1. **Better Maintainability**: Separated concerns between inference and fine-tuning
2. **Easier Integration**: Cleaner APIs for external frameworks (SGLang, LLaMA-Factory)
3. **Focused Development**: Dedicated modules with specific optimization goals
4. **Reduced Complexity**: Smaller, more manageable codebases

## ğŸ”— Related Resources

- **Main Repository**: [../README.md](../README.md)
- **kt-kernel Documentation**: [../kt-kernel/README.md](../kt-kernel/README.md)
- **KT-SFT Documentation**: [../KT-SFT/README.md](../KT-SFT/README.md)
- **Project Website**: https://kvcache-ai.github.io/ktransformers/

---

<div align="center">
  <sub>Archived on 2025-11 as part of repository restructuring</sub>
</div>
